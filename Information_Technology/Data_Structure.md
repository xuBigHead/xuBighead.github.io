# ARRAY

**数组**：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)，但在数 组中间以及头部插入数据时，需要复制移动后面的元素。



# LinkedList

**链表**：一种在物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。

链表由一系列结点（链表中每一个元素）组成，结点可以在运行时动态生成。每个结点都包含“**存储数据单元的数据域**”和“**存储下一个结点地址的指针域**”这两个部分。

由于链表不用必须按顺序存储，所以链表在插入的时候可以达到O(1)的复杂度，但查找一个结点或者访问特定编号的结点需要O(n)的时间。



## 单向列表

单向列表指每个节点都包含指向下一个节点的指针。



## 双向链表

双向链表的中间节点包含分别指向前后节点的指针，所以从任意位置开始都能快速访问其前后节点。

![双向链表](../../Image/2022/07/220716-1.png)



### 特点

- 创建双链表时无需指定链表的长度。
- 比起单链表，双链表需要多一个指针用于指向前驱节点，所以需要存储空间比单链表多一点。
- 双链表的插入和删除需要同时维护 next 和 prev 两个指针。
- 双链表中的元素访问需要通过顺序访问，即要通过遍历的方式来寻找元素。



## 双向循环链表

双向循环链表在双向列表的基础上，最后一个节点的 next 指向 head，而 head 的 prev 指向最后一个节点，构成一个环。

![双向循环链表](../../Image/2022/07/220716-2.png)



# Tree

由n（n≥1）个有限结点组成的一个具有层次关系的集合，就像是一棵倒挂的树。

在树形结构中，数据搜索速度与高度有关，树越高，性能越差。树的节点元素必须可以比较，不能比较的元素无法构成一棵树。



## 二叉搜索树

### 定义

二叉搜索树（Binary Search Tree），又叫二叉查找树，二叉排序树，二分搜索|查找|排序树。二叉搜索树具备如下特点：

- 二叉搜索树也是一棵二叉树；
- 二叉搜索树的任意结点A， 其左子树的所有结点的值都小于结点A的值，其右子树的所有结点都大于结点A的值；
- 二叉搜索树的左右子树也是一棵二叉搜索树；
- 二叉搜索树没有值相等的结点。



### 缺陷

<img src="../../Image/2022/05/220511-1.png" alt="20220511-2" style="zoom:80%;" />

二叉搜索树无法控制根节点的取值，导致会出现树的倾斜或层级过深，此时查询效率近似于链表（时间复杂度为O(n)）。



## 平衡二叉搜索树

### 定义

平衡二叉搜索树（Self-balancing Binary Search Tree）是在二叉搜索树的基础上演变而来。又称为AVL树，因为AVL算法是最先发明的自平衡二叉搜索树算法，既是最早的平衡二叉搜索树的具体算法实现，在其他算法没有出来之前，AVL树也就称为了平衡二叉树搜索树的代名词。

平衡二叉搜索树具备如下特点：

- 每个节点的左右子树的高度之差不超过1，也可以说每个节点的平衡因子需在[-1,1]范围之内；
- 其每一个子树均为平衡二叉搜索树。

为了避免发生二叉搜索树中的树的倾斜情况，平衡二叉搜索树加上了自平衡的功能，让二叉搜索树可以经受住各种的插入和删除，依然保持左右子树的平衡，近似完全二叉树化，**让查找的时间复杂度稳定在O(log2n)。**

平衡二叉树相比于二叉树来说，查找效率更稳定，总体的查找速度也更快，但是并不是基于平衡二叉树构建索引就可以的。因为每个磁盘块只放一个节点，每个节点只放一组键值对，当数据过大的时候，二叉树的节点就会非常多，树的高度也会变高，查找的效率也会变低！

**AVL树一般使用场景在于查询而弱于增加删除。**



#### 节点的高

<img src="../../Image/2022/05/220511-2.png" alt="20220511-2" style="zoom:80%;" />

节点的高指的是**以当前该节点为根节点的子树的高，就是当前节点的高**。



#### 平衡因子

平衡二叉搜索树的每个结点的平衡因子需要满足在`[-1,1]`范围之内。平衡因子可以通过使用`左孩子的高 - 右孩子的高` 的方式去计算得到。

如上图所示：

- 结点A的平衡因子 = 结点B平衡因子 - 结点C平衡因子 = 2
- 结点G的平衡因子 = 结点I平衡因子 - 0 = 1
- 结点I的平衡因子 = 0 - 0 = 0



#### LL，RR，LR，RL

当新插入一个元素后，该树出现了不平衡现象，**那么根据新插入元素与向上回溯找到的第一个不平衡结点的相对位置，可以分为如下四种情况：**

- LL：新插入元素是在向上回溯找到的第一个不平衡结点的左孩子的左侧的情况；
- LR：新插入元素是在向上回溯找到的第一个不平衡结点的左孩子的右侧的情况；
- RR：新插入元素是在向上回溯找到的第一个不平衡结点的右孩子的右侧的情况；
- RL：新插入元素是在向上回溯找到的第一个不平衡结点的右孩子的左侧的情况；



#### 左旋，右旋

左旋，右旋指的是对不平衡结点进行类似向左旋转和向右旋转的操作，最终让整棵二叉搜索树得以满足平衡特性。因为对不平衡结点的动作，就像将该不平衡结点进行左边旋转或右边旋转。

**LL，LR，RR，RL四种情况下的解决方式：**

- LL：对不平衡结点y进行右旋操作即可（右旋）
- LR：先对不平衡结点y的左孩子x进行左旋操作，得到对结点y的LL情况，再对不平衡结点y进行右旋操作（先左旋，后右旋）
- RR：对不平衡结点y进行左旋操作即可（左旋）
- RL：选对不平衡结点y的右孩子x进行右旋操作，得到对结点y的RL情况，再对不平衡结点y进行左旋操作(先右旋，后左旋)



**以下是一个`LL`情况的左旋操作，最终的到一棵满足平衡的二叉搜索树**

![20220511-3](../../Image/2022/05/220511-3.png)



**以下是一个`LR`的情况**

先通过左旋得到对节点y的LL情况，再按照LL情况进行右旋操作。

![20220511-4](../../Image/2022/05/220511-4.png)



### 缺陷

平衡二叉搜索树相较于二叉搜索树而言，树的高度更平衡，避免出现树的倾斜。但是在数据量较多的情况下，平衡二叉搜索树的高度还是过高。



## 多路平衡多路查找树

### 定义

#### 数据域

B树中每个结点存储数据的地方，就称之为数据域。数据域中存储的数据通常是一个个的键值对，键值对就分为`键(key)`和`值(value)`，这里通常称键为`关键字`，**也通常会将`关键字`直接指代整个键值对**。

站在数据库索引的角度，关键字就是用于建立索引的字段值，而对应的值就是该关键字所对应的目的数据，可以是主键信息，也可以指向实际数据的地址，甚至是完整的一行数据。



#### 指针域

二叉搜索树的节点有两个指针，既左孩子指针和右孩子指针。而这两个指针所在的区域，就称之为指针域。

B类树并不是一棵二叉树，它是一棵多叉树。一棵B类树，可能有多个指针，每个的结点的所有的指针所在的区域就是指针域啦。



### B - Tree

它是一棵多路平衡多路查找树。

单节点可以存储多个键值对的二叉平衡树，就是B树。

B树相对于平衡二叉树，每个节点存储了更多的键值和数据，每个节点有更多的子节点，子节点的个数称为阶，上图就是一个3阶B树，高度也会很低，这样B树的查找磁盘次数也会很少，这样数据的查找效率就会比平衡二叉树高。

![](../../Image/2022/04/220414-1.png)



#### 特点

对于一棵m阶（m叉）B-Tree来说（m >= 2）：

- 非叶子节点的节点最少有ceil(m/2)个子节点，最多m个子节点；
- 节点上最少有ceil(m/2)-1个键，最多有m-1个键；
- 自平衡的数据结构，所有叶子节点都在同一层；
- 节点中的键值信息符合如下条件：
    - 键升序排序；
    - 指针指向子节点；
    - 节点中的键左边指针指向的键小于当前键，右边指针指向的键大于当前键。



#### 相比优势

相比二叉搜索树，高度/深度更低，自然查询效率更高。



### B + Tree

B+ 树是对B树的进一步优化。



![](../../Image/2022/04/220414-2.png)



B+ 树和B 树有什么不同

1. B+ 树非叶子节点non-leaf node 上是不存储数据的，仅存储键，而B 树的非叶子节点中不仅存储键，也会存储数据。B + 树之所以这么做的意义在于；树一个节点就是一个页，而数据库中页的大小是固定的，innodb 存储引擎默认一页为16kb，所以在页大小固定的前提下，能往一个页中放入更多的节点，相应的树的阶数就会更大，那么树的高度必然更矮更胖，如此一来我们查找数据进行磁盘io次数又会再次减少，数据查询的效率也会更快。

2. B+ 树的阶数是等于键的数量的，列如我们的B+ 树中每个节点可以存储3个键，3层B+ 树可以存储`3*3*3=9`个数据。所以如果我们的B+ 树一个节点可以存储1000个键值，那么3层B+ 树可以存储`1000*1000*1000=10亿`个数据。而一般节点是常驻内存的，所以一般我们查找出10亿数据，只需要2次磁盘IO。

3. 因为B+ 树索引的所有数据均存储在叶子节点leaf node ，而且数据是按照顺序排列的。那么B+ 树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。而B 树因为数据分散在各个节点，要实现这一点是很不容易的。

	而且B+ 树中各个页之间也是通过双向链表连接的，叶子节点找那个的数据是通过单向链表连接的。其实在B 树中我们也可以多各个节点加上链表。其实这些不是它们之间的区别，是因为在mysql的innodb存储引擎中，索引及时这样存储的。也就是说B+ 树索引就是innodb中 B+ 树索引真正的实现方式，准确的说应该是聚集索引。

	在innodb中，我们通过数据页之间通过双向链表连接以及叶子节点中数据之间通过单向链表连接的方式可以找到表中所有的数据。

#### 特点

- B+树有两种类型的节点：内部结点（也称**索引结点**）和**叶子结点**。内部节点就是非叶子节点，内部节点不存储数据，只存储索引，数据都存储在叶子节点。
- 内部结点中的key都按照**从小到大**的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。
- 每个叶子结点都存有相邻叶子结点的指针，可以实现双向顺序访问，叶子结点本身依关键字的大小**自小而大**顺序链接。
- 父节点存有**右孩子的第一个元素的索引**。



#### 相比优势

- B+Tree的查询效率**更加稳定**。由于B+Tree只有叶子节点保存key信息，查询任何key都要从root走到叶子，所以更稳定。
- 只需遍历叶子节点，就可以实现整棵树的遍历。



#### B+Tree和B-Tree的区别

- B+Tree有n棵子树的结点中含有n个键值，B-Tree只有n-1个。
- B+Tree所有的键值信息只在叶子节点中包含，非叶子节点仅仅保存子节点的最小（或最大）值，和指向叶子节点的指针，这样相比B-Tree每一个节点在硬盘中存放了更少的内容（没有键值信息了）
- B+Tree所有叶子节点都有一个根据大小顺序指向下一个叶子节点的指针Q，本质上数据就是一个链表。

- 由于B+树的数据都存储在叶子结点中，叶子结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，而在数据库中基于范围的查询是非常频繁的，所以通常B+树用于数据库索引。
- B+树的节点只存储索引key值，具体信息的地址存在于叶子节点的地址中。这就使以页为单位的索引中可以存放更多的节点。减少更多的I/O支出。
- B+树的查询效率更加稳定，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。



## 红黑树

红黑树也是一种自平衡二叉查找树，它与AVL树类似，都在添加和删除的时候通过旋转操作保持二叉树的平衡，以求更高效的查询性能。

与AVL树相比，红黑树牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。



### 定义

- 节点非黑即红
- 整个树的根节点一定是黑色
- 叶子节点（包括空叶子节点）一定是黑色
- 每个红色节点的两个子节点都为黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)
- 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。



基于上面的原则，一般在插入红黑树节点的时候，会将这个节点设置为红色，原因参照最后一条原则，红色破坏原则的可能性最小，如果是黑色很可能导致这条支路的黑色节点比其它支路的要多1。

一旦红黑树上述原则有不满足的情况，我们视为平衡被打破，红黑树会通过变色、左旋、右旋的方式恢复平衡。变色指红变黑或黑变红。



### 平衡流程

**场景1 第一次插入**

RBTree第一次插入节点时，新节点会是红色，违背了原则二，直接将颜色变黑即可。



**场景2 父节点为黑色**

当插入时节点为红色且父节点为黑色，满足RBTree所有原则，已经平衡。



**场景3 父节点为红色且叔叔节点为红色**

父节点叔叔节点都为红色

**在平衡的过程中，要注意红黑树的规定原则。**

插入红节点，不能仅仅将父节点由红变黑，因为这样会增加这条支路的黑节点数，从而违反**“从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点”**。

将父节点和叔叔节点都变黑，再将祖父节点由黑变红，这样一来，以13为root的红黑树对外黑色节点数没变，对内各条支路节点数一致。



**场景4 父节点为红色，叔叔节点为黑色且新节点为右子树**

节点8的父节点为红，叔叔节点为黑，且通过左旋的方式，让整个情况变成下一个场景：父节点红色，叔叔节点为黑色且新节点为左子树。



**场景5 父节点为红色，叔叔节点为黑色且新节点为左子树**



# HASH

根据关键码值（Key value）直接进行访问的数据结构。通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做哈希函数，存放记录的数组就叫做哈希表。

从根本上来说，一个哈希表包含一个数组，通过特殊的关键码(也就是key)来访问数组中的元素。



哈希表的主要思想是:

- 存放Value的时候，通过一个**哈希函数**，通过 关键码（key）进行哈希运算得到哈希值，然后得到 映射的位置， 去寻找存放值的地方 ，
- 读取Value的时候，也是通过同一个**哈希函数**，通过 关键码（key）进行哈希运算得到哈希值，然后得到 映射的位置，从那个位置去读取。



## 哈希算法

哈希算法要符合一下几点要求：

- 高效：效率得高，要做到长文本也能高效计算出hash值；

- 不可逆：不能逆推出原文；

	

### 直接定址法

- 取关键字或关键字的某个线性函数值为散列地址。
- 即 f(key) = key 或 f(key) = a*key + b，其中a和b为常数。



### 除留余数法

- 取关键字被某个不大于散列表长度 m 的数 p 求余，得到的作为散列地址。
- 即 f(key) = key % p, p < m。这是最为常见的一种哈希算法。



###  数字分析法

- 当关键字的位数大于地址的位数，对关键字的各位分布进行分析，选出分布均匀的任意几位作为散列地址。
- 仅适用于所有关键字都已知的情况下，根据实际应用确定要选取的部分，尽量避免发生冲突。



### 平方取中法

- 先计算出关键字值的平方，然后取平方值中间几位作为散列地址。
- 随机分布的关键字，得到的散列地址也是随机分布的。



### 随机数法

- 选择一个随机函数，把关键字的随机函数值作为它的哈希值。
- 通常当关键字的长度不等时用这种方法。



## 哈希冲突

哈希冲突指的是不同的key通过同样的哈希算法生成的哈希值相同，也叫哈希碰撞。

哈希冲突是无法避免的，如果要完全避免的话，那么就只能一个key对应一个值的地址，也就是一个key就有一个索引。这样一来，空间就会增大，甚至内存溢出。



> 要想办法减少哈希冲突，**因为Hash碰撞的概率就越小，存取效率就会越高**



### 解决方案

#### 开放地址法

开发地址法的做法是，当冲突发生时，使用某种探测算法在散列表中寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到。

按照探测序列的方法，一般将开放地址法区分为线性探查法、二次探查法、双重散列法等。

这里为了更好的展示三种方法的效果，我们用以一个模为8的哈希表为例，采用**除留余数法**，

往表中插入三个关键字分别为26，35，36的记录，分别除8取模后，在表中的位置如下：

| 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|      |      | 26   | 35   | 36   |      |      |      |



这个时候插入42，那么正常应该在地址为2的位置里，但因为关键字30已经占据了位置。



##### 线性探查法

fi=(f(key)+i) ％ m ，0 ≤ i ≤ m-1

探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+1]，…，直到 T[m-1]，此后又循环到 T[0]，T[1]，…，直到探查到有空余的地址或者到 T[d-1]为止。

插入42时，探查到地址2的位置已经被占据，接着下一个地址3，地址4，直到空位置的地址5，所以39应放入地址为5的位置。

缺点：需要不断处理冲突，无论是存入还是査找效率都会大大降低。

| 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|      |      | 26   | 35   | 36   | 42   |      |      |



##### 二次探查法

fi=(f(key)+di) ％ m，0 ≤ i ≤ m-1

探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+di]，di 为增量序列12，-12，22，-22，……，q2，-q2 且q≤1/2 (m-1) ,直到探查到 有空余地址或者到 T[d-1]为止。

缺点：无法探查到整个散列空间。

所以插入42时，探查到地址2被占据，就会探查T[2+1^2]也就是地址3的位置，被占据后接着探查到地址7，然后插入。

| 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|      |      | 26   | 35   | 36   | 42   |      |      |



##### 双重散列法

fi=(f(key)+i*g(key)) % m (i=1，2，……，m-1)

其中，f(key) 和 g(key) 是两个不同的哈希函数，m为哈希表的长度

步骤：

双哈希函数探测法，先用第一个函数 **f(key)** 对关键码计算哈希地址，一旦产生地址冲突，再用第二个函数 **g(key)** 确定移动的步长因子，最后通过步长因子序列由探测函数寻找空的哈希地址。

比如，f(key)=a 时产生地址冲突，就计算g(key)=b，则探测的地址序列为 f1=(a+b) mod m，f2=(a+2b) mod m，……，fm-1=(a+(m-1)b) % m，假设 b 为 3，那么关键字42应放在 “5” 的位置。

| 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|      |      | 26   | 35   | 36   | 42   |      |      |



##### 总结

开发地址法，通过持续的探测，最终找到空的位置。

上面的例子中，开发地址方虽然解决了问题，但是26和42,占据了一个数组同一个元素，42只能向下，此时再来一个取余为2 的值呢，只能向下继续寻找，同理，每一个来的值都只能向下寻找。

为了解决这个问题，引入了链地址法。



#### 链地址法

在哈希表每一个单元中设置链表，某个数据项对的关键字还是像通常一样映射到哈希表的单元中，而数据项本身插入到单元的链表中。

来一个相同的数据，就将它插入到单元对应的链表中，在来一个相同的，继续给链表中插入。

链地址法解决哈希冲突的例子如下：

（1）采用**除留余数法**构造哈希函数，而 冲突解决的方法为 **链地址法**。

（2）具体的关键字列表为（19,14,23,01,68,20,84,27,55,11,10,79），则哈希函数为H（key）=key MOD 13。则采用除留余数法和链地址法后得到的预想结果应该为：

![img](../../Image/2022/08/220801-1.png)



哈希造表完成后，进行查找时，首先是根据哈希函数找到关键字的位置链，然后在该链中进行搜索，如果存在和关键字值相同的值，则查找成功，否则若到链表尾部仍未找到，则该关键字不存在。



哈希表的特性决定了其高效的性能，大多数情况下**查找元素**的时间复杂度可以达到O(1)， 时间主要花在计算hash值上，

然而也有一些极端的情况，最坏的就是hash值全都映射在同一个地址上，这样**哈希表就会退化成链表**。**查找元素**的时间复杂度会变为O(n)，效率瞬间低下。



## 最佳实践




# 参考资料
- [Data Structure Visualizations](https://www.cs.usfca.edu/~galles/visualization/Algorithms.html)